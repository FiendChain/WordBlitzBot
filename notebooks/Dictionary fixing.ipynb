{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import lxml.html\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Dictionary:\n",
    "    def __init__(self, mapping={}):\n",
    "        self.map = mapping\n",
    "\n",
    "    def add_word(self, word):\n",
    "        for i in range(len(word)):\n",
    "            branch = word[:i]\n",
    "            self.map.setdefault(branch, False)\n",
    "        \n",
    "        self.map[word] = True\n",
    "\n",
    "    def remove_word(self, word):\n",
    "        # if word not in, then do nothing\n",
    "        if not word in self.map:\n",
    "            return False\n",
    "        \n",
    "        is_word = self.map[word]\n",
    "        # if branch, do nothing\n",
    "        if not is_word:\n",
    "            return False\n",
    "\n",
    "        # if it is a word, check that it has no branches, and remove\n",
    "        self.map[word] = False \n",
    "        for i in range(ord('a'), ord('z')+1):\n",
    "            c = chr(i)\n",
    "            branch = word+c\n",
    "            if self.is_branch(branch):\n",
    "                break\n",
    "        # if no branches, then just remove\n",
    "        else:\n",
    "            self.map.pop(word)\n",
    "\n",
    "    def is_branch(self, word):\n",
    "        return word in self.map\n",
    "\n",
    "    def is_word(self, word):\n",
    "        return self.is_branch(word) and self.map[word] is True\n",
    "    \n",
    "class DictionarySerialiser:\n",
    "\n",
    "    def save(self, dictionary, path):\n",
    "        with open(path, 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(dictionary.map, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    def load(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            mapping = pickle.load(f)\n",
    "            dictionary = Dictionary(mapping)\n",
    "            return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 11\n",
    "filepath = f\"../assets/score_prediction/{folder}\"\n",
    "\n",
    "image = cv2.imread(f\"{filepath}/sample.png\")\n",
    "paths_df = pd.read_csv(f\"{filepath}/paths.csv\", delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_paths = {}\n",
    "for i, row in paths_df.iterrows():\n",
    "    word = row['word']\n",
    "    path = eval(row['path'])\n",
    "    score = row['score']\n",
    "    \n",
    "    selected_paths[word] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open as html\n",
    "with open(f\"{filepath}/results.html\", \"r\") as f:\n",
    "    results_html_string = f.read()\n",
    "    results_html = lxml.html.fromstring(results_html_string)\n",
    "    \n",
    "# fetch scores\n",
    "scores = {}\n",
    "score_list = []\n",
    "rows = results_html.cssselect(\"div.points-result\")[0]\n",
    "for row in rows:\n",
    "    word = row.cssselect(\"div.word\")[0].text_content()\n",
    "    points = int(row.cssselect(\"div.points\")[0].cssselect(\"div.left\")[0].text_content())\n",
    "    score_list.append((word, points))\n",
    "    scores[word] = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 invalid words\n",
      "20 missed words\n"
     ]
    }
   ],
   "source": [
    "invalid_words = []\n",
    "missed_words = []\n",
    "\n",
    "for word in scores:\n",
    "    if word not in selected_paths:\n",
    "        missed_words.append(word)\n",
    "\n",
    "for word in selected_paths:\n",
    "    # then word is invalid\n",
    "    if word not in scores:\n",
    "        invalid_words.append(word)\n",
    "        continue\n",
    "        \n",
    "print(f\"{len(invalid_words)} invalid words\")\n",
    "print(f\"{len(missed_words)} missed words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialiser = DictionarySerialiser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_filepath = \"../assets/dictionaries/dictionary.pickle\"\n",
    "dictionary = serialiser.load(dict_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 152 words, Added 20 words\n"
     ]
    }
   ],
   "source": [
    "removed_words = []\n",
    "added_words = []\n",
    "\n",
    "for word in invalid_words:\n",
    "    if dictionary.is_word(word):\n",
    "        removed_words.append(word)\n",
    "\n",
    "for word in missed_words:\n",
    "    if not dictionary.is_word(word):\n",
    "        added_words.append(word)\n",
    "\n",
    "print(f\"Removed {len(removed_words)} words, Added {len(added_words)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in removed_words:\n",
    "    dictionary.remove_word(word)\n",
    "    \n",
    "for word in added_words:\n",
    "    dictionary.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialiser.save(dictionary, dict_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
