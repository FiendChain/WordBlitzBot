{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import lxml.html\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Dictionary:\n",
    "    def __init__(self, mapping={}):\n",
    "        self.map = mapping\n",
    "\n",
    "    def add_word(self, word):\n",
    "        for i in range(len(word)):\n",
    "            branch = word[:i]\n",
    "            self.map.setdefault(branch, False)\n",
    "        \n",
    "        self.map[word] = True\n",
    "\n",
    "    def remove_word(self, word):\n",
    "        # if word not in, then do nothing\n",
    "        if not word in self.map:\n",
    "            return False\n",
    "        \n",
    "        is_word = self.map[word]\n",
    "        # if branch, do nothing\n",
    "        if not is_word:\n",
    "            return False\n",
    "\n",
    "        # if it is a word, check that it has no branches, and remove\n",
    "        self.map[word] = False \n",
    "        for i in range(ord('a'), ord('z')+1):\n",
    "            c = chr(i)\n",
    "            branch = word+c\n",
    "            if self.is_branch(branch):\n",
    "                break\n",
    "        # if no branches, then just remove\n",
    "        else:\n",
    "            self.map.pop(word)\n",
    "\n",
    "    def is_branch(self, word):\n",
    "        return word in self.map\n",
    "\n",
    "    def is_word(self, word):\n",
    "        return self.is_branch(word) and self.map[word] is True\n",
    "    \n",
    "class DictionarySerialiser:\n",
    "\n",
    "    def save(self, dictionary, path):\n",
    "        with open(path, 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(dictionary.map, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    def load(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            mapping = pickle.load(f)\n",
    "            dictionary = Dictionary(mapping)\n",
    "            return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 0\n",
    "filepath = f\"score_prediction/{folder}\"\n",
    "\n",
    "image = cv2.imread(f\"{filepath}/sample.png\")\n",
    "paths_df = pd.read_csv(f\"{filepath}/paths.csv\", delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_paths = {}\n",
    "for i, row in paths_df.iterrows():\n",
    "    word = row['word']\n",
    "    path = eval(row['path'])\n",
    "    score = row['score']\n",
    "    \n",
    "    selected_paths[word] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_words = []\n",
    "missed_words = []\n",
    "\n",
    "for word in scores:\n",
    "    if word not in selected_paths:\n",
    "        missed_words.append(word)\n",
    "\n",
    "for word in selected_paths:\n",
    "    # then word is invalid\n",
    "    if word not in scores:\n",
    "        invalid_words.append(word)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_words = []\n",
    "missed_words = []\n",
    "\n",
    "for word in scores:\n",
    "    if word not in selected_paths:\n",
    "        missed_words.append(word)\n",
    "\n",
    "for word in selected_paths:\n",
    "    # then word is invalid\n",
    "    if word not in scores:\n",
    "        invalid_words.append(word)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialiser = DictionarySerialiser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 260 words, Added 29 words\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../assets/dictionaries/dictionary.pickle\"\n",
    "dictionary = serialiser.load(filepath)\n",
    "\n",
    "for word in invalid_words:\n",
    "    dictionary.remove_word(word)\n",
    "\n",
    "for word in missed_words:\n",
    "    dictionary.add_word(word)\n",
    "\n",
    "print(f\"Removed {len(invalid_words)} words, Added {len(missed_words)} words\")\n",
    "    \n",
    "serialiser.save(dictionary, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
